 面试官您好，我是广东工业大学网络工程专业的陈豪。我的技术栈包括 K8S、Prometheus、Docker、CI/CD、Golang 以及 Python/Shell 自动化运维脚本开发，具备扎实的云原生与自动化运维能力。
 
>
> 我个人最大的优势是善于利用AI工具协同开发。例如，我能够根据不同任务灵活选择AI模型，编写Prompt，结合Project Rules，快速实现自动化脚本和平台功能。实际工作中，我乐于尝试新工具，关注前沿AI模型工具的使用，是 Cursor、Augment 和 Trae 的忠实用户，但因为cursor最近Claude等模型锁国区,Augment对coding能力尚可，但对上下文读取能力太差，所以在体验新推出的通义千问Qwen3。


## **系统监控**
- `top` → **P**(CPU排序) **M**(内存排序) **q**(退出)
- `free -h` → 查看内存使用，**available<10%告警**
- `df -hT` → 查看磁盘使用
- `iostat -x 1` → IO监控，**%util>80%关注**
- `netstat -tulnp` / `ss -tulnp` → 查看端口占用
- ‘nslookup' 查域名对应ip
- ps aux：显示所有进程的详细信息
- uname -r 查看内核版本
---
两台linux服务器上的文件怎么确定其是否相同
 “通常我们会对两个文件分别求哈希值（比如用md5sum、sha256sum），如果哈希值相同，基本可以认为文件内容一致。但哈希算法理论上存在冲突，极端情况下不同内容也可能哈希值一样，不过实际概率极低。对于安全性要求极高的场景，可以用更强的哈希算法，或者直接做二进制比对。”

查找目录下的大文件
“可以用find命令配合-size参数查找大文件，比如find /dir -type f -size +100M，查出来的就是大于100M的文件。”

如何查找名为abc的文件？如何模糊查找包含example的文件？
find / -iname "abc" 
find / -iname “*example”

普通哈希跟一致性哈希的区别
普通哈希跟一致性哈希都是负载均衡里面的概念。比如说又useer=1001，有ABC三台服务器，普通哈希就是用hash(1001)%3,用这个结果来选择服务器，缺点是假如新增服务器，旧有的缓存都会失效。
而一致性哈希则是将服务区与用户放到同一个环上，对用户取hash，然后找到换上离这个结果最近的服务区，优点是新增服务器只用更改相邻数据的位置
# / 指的是在 整个文件系统查找 , 如果选择 “.”则是在当前目录查找

如何查找日志文件中包含location的行？
grep "location" /var/log/nginx/access.log

如何查看已有防火墙规则？如何清空规则
使用iptabels -L查看已有的规则
使用iptabels -t 表名 -F 删除特定表的规则

df看见还有空间但是写不进去什么原因
1. inode索引节点用完了，无法再新建文件
2. 当前用户没有写入权限
3. 该文件被其他进程引用了,或者被其他vim加了锁.
4. 系统可能对用户设置了磁盘配额,超出后无法写入
5. 文件系统因为异常被挂载成了只读
6. 磁盘被给root用户给保留的空间.
7. 挂载点失效

怎么查看某个进程的进程号
ps aux | grep 进程名

描述Linux内存管理中的OOM Killer机制。
当系统可用内存极低同时无法通过回收缓存/swap的方式来满足新的内存分配需求时，就用通过一套打分机制来选出source最高的进程，比如说进程运行时间，优先级，占用内存大小等。求出来最高的进程之后，会将它杀死

进程的优先级范围是？
-20，19
19的优先级最低

描述systemd的工作原理和优势。如何创建和管理自定义的systemd服务单元？
systemed能并行启动，同时启动多个服务，提升启动速度。同时，它自动帮我们处理服务之间的依赖关系，统一用service文件来管理所有资源，便于我们进行统一管理
创建和管理自定义服务单元，我们需要去/etc/systemed/system底下创建我们的service文件，里面写有bin的配置以及相关配置，最后reload加载并启动对应服务即可

systemed能并行启动什么意思
多个systemd的service不同服务能够并行启动，并智能处理依赖。


CPU突刺问题一般是有哪些原因
. **进程异常**：存在僵尸进程或进程锁，持续占用CPU资源
2. **业务高峰**：业务流量突增，导致CPU使用率瞬时升高
3. **内存不足**：内存不足时频繁使用swap，IO等待导致CPU使用率不稳定
4. **系统调用频繁**：大量网络IO、磁盘IO导致系统调用开销增加
5. **CPU密集型任务**：加密解密、压缩解压等计算密集型操作
6. **调度器问题**：CPU调度器配置不当或负载不均衡

如果说某个服务CPU负载过高，你怎么排查
1. 首先iostat -x 1 检查一下是不是进程锁太多了导致占用了cpu
2. 其次 free -h 查看内存使用情况，看看是不是可用内存太少了，导致频繁交互内存sawp，磁盘IO过多导致CPU长期被占用
3. 跟业务沟通，看看是不是业务量增加导致 对CPU资源 有更高的要求，若有则考虑扩充服务器资源
4. 理论上不应该有这种情况发生，我们是有告警机制的，需要排查一下是不是告警转发失效，或者 告警规则配置漏了
5. 查看服务的数据库连接情况，检查是不是 慢查询过多，如果使用连接池，看看是不是连接池满了，需要扩充连接池。或者协调业务减少长链接，优化组合索引提高查询效率
6. 查看历史CPU使用趋势，看是偶发还是持续高负载

Linux如果要安装某个工具，不能出网，怎么办
用u盘拷贝

Linux的页最小单位是什么
Linux的页最小单位是4KB

什么是孤儿进程，系统会怎么解决
   孤儿进程：父进程已结束，但子进程仍在运行的进程
   系统解决：init进程（PID=1）自动收养孤儿进程，负责其生命周期管理

请你详细解释一下僵尸进程（Zombie Process）是什么？它为什么会出现？以及在实际运维中，我们应该如何处理僵尸进程？
   僵尸进程是子进程已死，但父进程未对其进行回收，导致的出现占用进程表项，但不占用内存的情况。它出现的原因可能是父进程设计错误，没有回收子进程的流程；也可能是父进程异常退出，导致子进程未被回收；最后一种可能是 父进程被io阻塞了，无法正常回收进程

零拷贝说一下
请你详细解释一下零拷贝（Zero Copy）技术。什么是零拷贝？它解决了什么问题？在Linux系统中，零拷贝是如何实现的？以及在实际应用中，零拷贝技术主要用在哪些场景？
零拷贝是数据从磁盘文件 → 内核缓冲区 → 网卡。系统从磁盘读取数据后，将数据写到内核的页面缓存，同时将缓存的地址以及长度发给网卡，网卡通过DMA来获取数据。不再经过用户空间，同时避免了cpu的频繁参与

内核缓冲区是什么
内核缓冲区是内核在内存开辟的一块位置，用来临时存储数据

内存本身不就能存储数据吗，为什么要用到内核缓冲区
因为假设数据存到用户内存区，那同一样的数据可能被存多次，同时用户内存区不可靠，其中一个程序崩了，用户内存区的数据也就没了。内核缓冲区相当于一个中信银行，统一存放数据

切换上下文又指的是什么
也就是在用户态和内核态之间切换

在Linux系统中，软链接（Symbolic Link）和硬链接（Hard Link）是两种不同的文件链接方式。请你详细解释一下它们的区别是什么？在什么情况下你会选择使用软链接，什么情况下会选择硬链接？以及在实际运维中，这两种链接方式各有什么优缺点？
软链接是类似于一个快捷方式，连接的文件里就显示着被链接文件的路径，有不同的inode号，比如说A是B的软链接,你访问A实际上默认是访问到B去。而硬连接不同，硬链接相当于直接把给当前inode再创建一个指针，无论是A亦或者是B访问，最终访问的都是这个inode，修改也是直接修改的这个inode。一般来说在跨文件系统或者需要更灵活的链接方式时会考虑软链接，但是假如你的文件路径需要频繁发生变化的，那就选硬链接。在实际运维中，软链接可能发生连接丢失，容易找不到文件，但是链接信息了然，能直接看到哪个是哪个都软链接。硬链接不够灵魂


LNUX内核怎么管理内存空间
"Linux内核的内存管理非常复杂，主要分为几个层次：
第一个是物理内存管理，内核维护一个页面帧数组，记录每个物理页面的状态，比如是否空闲、是否被使用。
第二个是虚拟内存管理，每个进程都有自己的虚拟地址空间，通过页表映射到物理页面。
第三个是内存分配器，比如伙伴系统、slab分配器，负责分配和释放内存。
第四个是内存回收机制，当内存不足时，会回收一些内存，比如写回脏页、交换到磁盘。
还有就是内存压缩、内存热插拔等高级功能。"

说一下linux的用户态与内核态
用户态（User Mode）
定义： 程序运行在用户空间，只能访问受限的系统资源
权限： 权限较低，不能直接访问硬件和内核资源
用户态主要负责：
计算处理
业务逻辑
内存管理
算法实现
内核态（Kernel Mode）
定义： 操作系统内核运行的状态，拥有最高权限
权限： 可以访问所有系统资源，包括硬件
内核态主要负责：
硬件访问
系统资源管理
进程调度
安全控制


描述切换到具体过程
"切换过程大概分几步：
首先得保存当前状态，就像暂停游戏一样，把当前的工作状态都记下来。
然后提升权限等级，从普通权限提升到最高权限。
接着切换工作空间，从用户的工作空间切换到系统的工作空间。
然后系统就开始干活了，执行用户请求的操作。
干完了就恢复之前的状态，再切换回用户态，程序继续运行。
整个过程虽然复杂，但CPU处理得很快，一般几微秒就搞定了。"

父进程与子进程的区别与关系，以及如何查看一个进程的父进程与子进程
1. 父进程与子进程的关系
父进程：创建其他进程的进程，每个进程（除init）都有父进程
子进程：被其他进程创建的进程，继承父进程资源

没有单个命令能同时显示父进程和子进程
ps -p 中的ppid是父进程
pgrep -P 126 直接看子进程      pgrep 为 process grep的缩写
pstree -p 看子树，也就是子进程

linux系统里面，它那个平均负载，你知道怎么是怎么计算的吗？
平均负载的定义
平均负载表示系统中可运行状态和不可中断状态的进程数量，包括：
可运行进程：正在运行或等待CPU的进程
不可中断进程：正在等待内核完成I/O操作的进程（如磁盘I/O、网络I/O）

怎么设置一个临时的ip地址，不是设置静态ip地址
sudo ip addr add 192.168.1.100/24 dev eth0

文件描述符是什么
文件描述符是操作系统内核为每个打开资源分配的唯一身份证，程序利用这个身份证来进行文件操作

解释Linux中的文件描述符限制。
文件描述符限制是操作系统为了避免线程无限制打开文件导致崩溃或者是占用太多内存空间，同时为了公平性考量， 给进程上的最大可同时打开文件的闲置

说说负载均衡的反向代理机制
 “反向代理就是客户端请求先到代理服务器，由代理服务器决定转发到哪个后端。负载均衡器会根据规则分发流量，并做健康检查，保证高可用和均衡负载。”

乐观锁和悲观锁
乐观锁：
机制：不加锁，只在提交时检查数据是否被修改
实现方式：使用版本号、时间戳、CAS操作
特点：并发性能好，但可能提交失败需要重试
适用场景：读多写少，冲突较少的场景
悲观锁：
机制：先加锁，再操作数据，操作完再解锁
实现方式：数据库行锁、表锁、共享锁、排他锁
特点：保证数据一致性，但并发性能较差
适用场景：写多读少，冲突较多的场景

Linux怎么配置路由
Linux 配置路由用 route 或 ip route 命令，添加、删除、查看都很方便，永久生效要写配置文件。

脚本能直接执行，但是cron里面就不能直接执行
1. 可能是我们的环境变量没导入
2. corn默认工作目录是 用户的~目录，如果脚本存在相对路径可能找不到文件
3. 脚本没有执行权限，或者crontab所属的用户没有访问 某些文件/目录的权限。
4. 脚本依赖没加载
5. crontab格式写错导致定时任务没被正常执行
6.存在shell类型不同导致不兼容，contab默认用 sh而非bash

操作系统中断的区别
 “操作系统的中断分为外部中断和内部中断。外部中断来自硬件，比如键盘、网卡等；内部中断是CPU执行过程中遇到的异常，比如除零、非法访问。还有一种软件中断，是程序主动触发的，比如系统调用。三者的区别主要在于来源和用途。”

 中断的作用
打断CPU当前的工作，让它去处理更紧急或重要的事情
实现异步处理，提高系统效率和响应速度

什么情况用户态进入内核 具体哪些操作呢
 “用户态进入内核态，最常见的是系统调用，比如读写文件、网络通信、进程管理等。还有程序异常（比如除零、非法访问）、外部设备中断（比如键盘输入、网络数据到达）、信号处理等情况，都会让CPU从用户态切换到内核态，由操作系统来处理。”
 6. 一句话总结
只要用户程序需要操作系统帮忙干活，或者遇到异常/中断，就会从用户态切换到内核态。

linux，修改文件命令失败可能有哪些原因导致的？
1. 最常见的，没有写的权限
2. 可能该文件被创建时就挂载到了只读模式
3. 文件可能被加锁，或者文件被某些程序独占打开
3. 磁盘空间不足，无法正常写入
4. 系统vim打开时会创建临时文件，可能影响相关操作

虚拟内存是什么
是系统为了缓解内存不足临时使用磁盘进行IO读写而扩展出来的内存。

虚拟内存和正常内存它们在运行效率上有区别吗
有显著区别，物理内存读写速度很快，纳秒级，而虚拟内存因为需要 进行磁盘IO的读写操作,所以运行效率较慢,同时频繁使用swap进行内存交换容易导致cpu利用率上升导致卡顿,因为磁盘IO会阻塞进程

面试官：为什么频繁使用swap会导致CPU利用率上升？
标准答法：
回答：
"磁盘IO本身不直接消耗CPU，但是会间接影响CPU。当系统大量使用swap时，进程需要等待磁盘IO完成，这时候CPU会进入等待状态，等待时间越长，CPU利用率看起来就越高。"

堆和栈的区别
1. 管理方式
栈：系统自动管理，函数调用时分配，返回时释放
堆：程序员手动管理，需要malloc/free
2. 空间大小
栈：空间有限，通常几MB，容易栈溢出
堆：空间很大，受系统内存限制
3. 访问速度
栈：访问速度快，直接操作内存
堆：访问速度慢，需要指针间接访问
4. 内存碎片
栈：不会产生内存碎片
堆：会产生内存碎片，需要垃圾回收
5. 线程安全
栈：每个线程有独立的栈空间
堆：所有线程共享堆空间，需要同步

在Linux系统中，进程间通信（IPC）是一个重要的概念。请你详细解释一下Linux中常见的进程间通信方式有哪些？每种方式的特点是什么？在实际应用中，你会如何选择合适的IPC方式？
常见通信方式有 套接字，信号量，信号，共享内存，管道。套接字的特点是可以参与网络通信，跨主机，适合客户端服务端通信。信号量的特点是原子态，跟资源同步，比较适合多进程同步。信号的特点是异步，简单，但是有些不可靠。共享内存的特点是多个进程共享一块内存，优点是通信速度快，但是可能导致竞争状态。管道开销小，但是只能单向传递字节流，比较适合父子进程通信。

在Linux系统中，虚拟内存（Virtual Memory）是一个重要的概念。请你详细解释一下什么是虚拟内存？它是如何工作的？以及在实际运维中，我们如何监控和管理虚拟内存？
虚拟内存为每个进程提供独立的虚拟地址空间,有进程见的内存隔离.一般来说,当物理机的内存不足时,磁盘存储就会分一部分不常用的存储空间作为交换地址,以频繁磁盘IO进行读写达到交换内存的作用，可以有效提升系统的内存可用量。

在Linux系统中，网络配置和故障排查是运维工程师的重要技能。请你详细解释一下如何排查网络连接问题？如果用户反映无法访问某个网站，你会按照什么步骤来排查？
1. 首先是在自己本地机访问该网站看看能不能访问到
2. 其次是使用nslookup 查看域名解析正不正常，使用curl -v 查看详细的网络跳转情况，使用ping对应的ip看网络报文的反馈情况。
3. 如果网站通过负载均衡进行流量转发，可能得连到部署负载均衡的服务器查看日志，看哪个流量转发超时了
4. 连到部署了这个网站的服务器本身，查看内存，存储，cpu利用率情况。检查pod重启情况，看是不是某个节点宕机了导致该情况发生。
4. 检查防火墙策略和云安全组，检查web服务有没有启动，
5. 如果连接有mysql，redis，可能得排查一下慢查询，以及连接池情况

假设你负责维护一个高并发的Web应用，突然收到告警说服务器CPU使用率飙升到90%以上，同时用户反馈网站响应很慢。作为SRE工程师，你会如何快速定位和解决这个问题？
1. 首先是网络上的，nslookup查看dns解析正不正常，ping对应ip，curl -v查看报文相应状态码
2. 再次是负载均衡，查看日志，检查有没有流量转发超时代情况。
3. 再次是连到服务器上，top 查看利用CPU最高的进程是什么，再使用lsof + pid 查看进程的状态。
4. ps aux检查进程状态，杀死僵尸进程。
4. instat检查磁盘io读写情况，内存，磁盘存储量，可能是内存不够，导致磁盘频繁io，堵塞了io进程，进程堆积。先删除日志文件+清理一部分缓存，在流量低谷期进行重启
5. 跟业务沟通服务器有没有新部署什么东西，看是不是最近业务新增了 cpu密集型程序，或者业务量增大需要扩容。
6. 检查mysql慢查询和redis连接池，看是不是慢查询太多导致超时，连接池满了导致redis连接一直等待。
7. 最后是检查redis缓存情况，看是不是有某个热点key过期了导致缓存击穿，大量并发请求打到数据库，这种情况需要紧急将该热点key进行重新缓存并设置永不过期


假设您要设计一个支持10万并发用户的电商系统，从用户下单到支付完成的完整流程，
我草，这个是SRE运维工程师面试要回答的题目吗。
1. 是采用CDN，将前端图片等数据缓存至CDN
2. 对于数据库请求，采用redis进行缓存，需要采用布隆过滤器+空值存储来防止缓存穿透，随机过期时间，以及缓存预热，即在查询前先在缓存处预热一部分数据，同时设置熔断机制，当大量请求同时打到数据库时返回降级的缓存历史数据来实现防止缓存血崩；热点key永不过期，对并发请求上锁，在缓存重建阶段只让第一个请求连到数据库，再存储到缓存处实现防止缓存击穿。
3. 对于数据一致性，需要在应用层采用幂等，使用唯一订单号使得用户点击一次和点击多次的结果是一致的设计模式，同时设置半同步复制以及故障转移机制机制，即定期检查主库的延迟情况，若出现高延迟时，当三个节点同意时选择延迟最低的从库转换为主库。当数据库出现宕机时实现主库的快速转移进行高可用设计。如果redis缓存压力较大，可以考虑使用redis哨兵模式做到redis主节点宕机实时切换
4.对于负载均衡，可能需要在负载均衡处配置多台后端服务器利用轮询权重机制进行流量的分流

面试官： 现在给你一个Linux进程管理的问题：
我们公司的一台服务器，发现某个进程占用了大量CPU资源，导致系统响应很慢。
问题： 请详细说明你会怎么排查和处理这个问题？包括如何找到问题进程、如何分析原因、如何应急处理等。
1.使用 top或者ps aux命令查看是哪个进程占用cpu情况异常高
2. 再用lsof命令查看这个进程打开的文件，临时文件多不多，路径是不是很奇怪，判断进程是不是异常进程
3. 使用 ps -ef | grep "PID"命令查看该进程的父进程，检查该父进程是不是  未知有病毒的父进程
4. 如果父进程正常，但是利用率高，那需要结合 df -hT以及free -h判断是不是业务量增大导致的特定进程的利用率提高
5. 可能是该进程运行的内存不够，需要频繁swap io磁盘，导致cpu占用率提高
5. 同时，也有可能是程序出现了循环调用，或者是 进程回收机制不完善导致的进程数过多。
6. 解决方法的话 看能不能把他kill掉，不能kill掉就先rince降低它的优先级，同时需要考虑扩充服务器资源

面试官： 现在给你一个文件权限问题：
我们公司的一个应用程序无法读取某个配置文件，但是文件确实存在。
问题： 作为SRE工程师，你会怎么排查这个文件权限问题？请详细说明你的排查思路和具体步骤。
1. 首先是这个文件本身，我们需要判断如果程序是直接运行中系统里的，那就需要判断运行程序的用户它本身有没有访问这个文件的权限，或者是程序里面的配置文件路径写错了
2. 再到docker，如果是用docker起的程序，那可能是配置文件没有挂载到docker上，docker无法直接访问宿主机上的配置文件。虽然docker在宿主机的默认权限是普通用户，配置文件可能是root用户创建的，没权限访问。
3. 如果程序是通过CI/CD部署的，那就可能是当前gitlab-runner用户没有读取文件的权限



假设你的服务器突然出现大量连接超时，用户反馈网站无法访问。通过监控发现网络连接数异常高，但CPU和内存使用率正常。作为SRE工程师，你会如何分析这个问题？可能的原因有哪些？你会采取什么措施来解决？
1. 可能是连接数限制，打到了最大连接数
2. time_wait太多，短联接导致连接耗尽，这种情况的话可能得修改内核参数，启用长连接，减少tiem_wait时间，复用上次的tcp端口
2. 后端服务器健康检查失败。
1.检查负载均衡服务器，看日志有哪些超时连接以及它们的跳转情况。
1.检查负载均衡，看是不是其他几个部署了web服务的节点挂了，全部流量都被发到这个服务器导致熔断。
3.redis连接池满了
4.缓存击穿/缓存雪崩，触发了熔断机制

怎么临时更换ip地址
1.使用ipaddr ip addr add ip eth0
2. 使用ifconfig eth0 ip {子网}

iptables的几个链表可以简单说一下吗
1. 首先是raw表，进行连接跟踪，标记数据包
2. 其次是mangle表，这个表设置数据包标记并修改ttl值
3. 其次是nat表，进行目标地址转换
4. 最后是fillter表，实现数据包的过滤

cookie和session都是什么？他们有什么区别？
Cookie是存储在客户端的小文件，Session是存储在服务器端的数据
具体区别
1. 存储位置
Cookie：存储在客户端浏览器
Session：存储在服务器端
2. 安全性
Cookie：不安全，容易被篡改，可以设置httpOnly
Session：相对安全，数据在服务器端
3. 存储容量
Cookie：通常4KB，存储有限
Session：受服务器内存限制，存储较大
4.生命周期
Cookie：可以设置过期时间，长期有效
Session：通常浏览器关闭就失效，也可以设置过期时间
5. 使用场景
Cookie：记住登录状态、用户偏好设置
Session：存储敏感信息、购物车数据

了解过CDN吗?
"CDN是内容分发网络，通过在全球各地部署节点服务器，让用户就近访问，提高访问速度。比如用户在北京访问网站，CDN会从北京的节点返回数据，而不是从上海的源站。"

linux删除文件的步骤
在Linux中，文件的删除实际上分为两个步骤：
删除文件名：从目录中移除文件名链接
释放磁盘空间：当没有进程引用该文件时，才真正释放磁盘空间

如果有一个文件夹叫data占用磁盘空间很多， 但是你cd进去后发现是空的，有哪些原因导致
1. 可能是里面都是 隐藏文件，使用ls -a才能看到
2. 可能缓存文件都被存放到里面去了，我们cd进去看不到
3. 存在已经删除，但是还被进程引用，所以没被释放的文件
4. 权限问题，可能当前用户没办法看到该文件
5. 软链接可能指向了大文件


什么命令可以直接查看某个文件是被哪些进程占用的
lsof +文件路径


操作系统消费者和生产者 如果使用同一块内存怎么避免
必须加锁或者用信号量等同步机制，保证同一时刻只有一个在操作
 "生产者-消费者用同一块内存时，用两个信号量：empty控制空位置数量，full控制已占用位置数量，再加一个mutex保证互斥。生产者先申请空位置再写，消费者先申请已占用位置再读，这样就能避免冲突和死锁。"

信号量是什么：
 "信号量就是一个计数器，记录可用资源数量。进程用资源时计数器减1，用完加1。如果计数器为0，想用资源的进程就得等待。操作系统用P操作申请资源，V操作释放资源。"


那我们想要删除掉被进程引用的文件应该怎么做?
lsof | grep deleted
再kill掉对应的进程

DNS是基于什么协议的

如果磁盘打满了你怎么做，说一下你的排查思路
第一步：快速诊断和应急处理
> "首先我会快速检查磁盘使用情况，确认问题严重程度。同时进行紧急处理，比如清理日志文件、临时文件等，快速释放一些空间，确保系统基本可用。"
第二步：根因分析
> "然后我会分析是什么原因导致磁盘打满。可能是业务量增长导致日志量激增，也可能是某个进程异常写入大量数据，或者是日志轮转机制失效。通过分析大文件、检查进程状态来定位具体原因。"
第三步：业务评估和沟通
> "接下来我会评估当前服务状态，与业务方沟通是否可以短暂重启服务。如果可以，我会在业务低峰期进行重启操作，释放更多空间。"
第四步：告警机制检查
> "理论上不应该出现磁盘突然打满的情况，所以我会检查监控告警是否正常工作。如果告警失效，需要立即修复监控系统，避免类似问题再次发生。"
第五步：长期解决方案
> "最后我会根据根因分析结果，制定长期解决方案。如果是业务增长导致的，考虑扩容磁盘；如果是日志管理问题，完善日志轮转策略；同时优化监控告警机制，确保提前发现问题。"

ubuntu系统下，如何配置网络，配置文件在哪
ubuntu 17.10 以后/etc/netplan/
以前 /etc/network/interfaces

一台服务器连接另一台服务器的 MySQL用什么命令？
mysql -h 192.168.1.100 -P 3306 -u user -p db

用户反馈系统卡顿怎么排查？
一是 先自己连一下看看是不是用户那边网络卡了
二是 ping 服务器的ip，看能不能正常ping通
三是 连接服务器，检查部署系统的服务器是否内存满了/磁盘满了/IO进程太多处理不过来了
四是 看一下相关服务的日志，重点关注报错、慢查询、超时等异常信息。
五 如果确实存在内存/磁盘满了，首先要 找找僵尸进程，kill掉，然后考虑优先重启 服务器保证服务，再观测
内存/磁盘使用情况，如果确实因为业务量增大导致服务器资源不够，考虑提高服务器资源分配。同时得同步排查一下
为什么告警没有正常触发
五是 如果系统有连接redis服务的，检查redis连接池看看是不是连接池满了


---

## **高并发网站备份策略**
**服务器网站访问量较大的时候如何备份？**
> 网站访问量大时，为避免影响线上业务，建议采用**热备份工具**、**云服务器虚拟机的快照技术**、**数据库主从架构下从库备份**，并选择业务低峰期执行。备份过程可限速、分批进行，确保业务高可用和数据一致性。

---

## **高负载服务器排查思路**
**场景：八核服务器，负载高达333、340、300，如何分析原因？**

1. **top/htop**：查看CPU、内存、进程占用，重点关注CPU占用高的进程、是否有大量`D`（不可中断IO）或`R`（运行中）状态的进程。
2. **free -h**：检查内存是否充足，是否有大量swap使用，内存不足会导致频繁swap，进而拖慢系统。
3. **iotop**：查看磁盘IO是否成为瓶颈，是否有进程大量占用IO。
4. **ps aux**：查找是否有僵尸进程（STAT列中为`Z`的是僵尸进程）、阻塞进程，分析进程状态。
5. **dmesg**：查看系统日志，排查是否有硬件故障、内核异常等。
6. **网络排查（如有必要）**：`ss -tulnp`、`iftop`等，排查网络流量异常。
7. **综合分析**：根据上述信息，定位是CPU、内存、IO还是网络瓶颈，针对性优化。

---

## **线程与进程的区别**
- **进程**：系统分配资源的基本单位，拥有独立的内存空间和资源，进程之间相互独立。
- **线程**：进程中的执行单元，是操作系统调度的最小单元。同一进程内的多个线程共享内存和资源，通信效率高但容易有同步问题。
- **适用场景**：进程适合高隔离、稳定性要求高的场景，线程适合高并发、轻量级任务。

---

## **进程间通信方式**
1. **常见的进程间通信方式**
   - **管道（Pipe）**
     - 匿名管道：父子进程间通信，单向传递数据，常用于shell命令的`|`。
     - 命名管道（FIFO）：不同无亲缘关系的进程也能通信，基于文件系统的特殊文件。
   - **信号（Signal）**
     - 用于进程间发送简单的通知或控制命令（如终止、暂停、唤醒等）。
     - 例如：`kill -9 1234` 向进程1234发送SIGKILL信号。
   - **消息队列（Message Queue）**
     - 进程可以向消息队列写入消息，其他进程可以读取，实现异步通信。
     - 适合多对多、异步、解耦的场景。
   - **共享内存（Shared Memory）**
     - 多个进程可以映射同一块物理内存，直接读写数据，速度最快。
     - 但需要配合信号量/互斥锁等机制保证同步和互斥。
   - **信号量（Semaphore）**
     - 主要用于进程间同步，控制对共享资源的访问（加锁/解锁）。
   - **套接字（Socket）**
     - 支持本机或网络上的进程通信，既可以本地通信（UNIX域socket），也可以跨主机通信（TCP/UDP）。
     - 适合分布式、网络服务等场景。
2. **它们是如何通信的？**
   - **管道/消息队列/套接字**：操作系统内核负责数据的缓冲和传递，进程通过读写接口进行通信。
   - **共享内存**：进程直接访问同一块内存区域，效率高，但需要同步机制防止数据冲突。
   - **信号**：操作系统向目标进程发送信号，进程收到后执行相应的处理函数。
   - **信号量**：用于加锁/解锁，保证多个进程对共享资源的有序访问。
---

## **同步和异步的区别**
- **同步**：指的是发起方在发出请求后，必须等待对方处理完成并返回结果，才能继续后续操作。比如：你打电话给别人，只有对方接听并回应，你才能继续下一步。
- **异步**：指的是发起方在发出请求后，不需要等待对方处理完成，自己可以继续做其他事情，对方处理完后再通过回调、通知等方式告知结果。比如：你发短信给别人，发完就可以做别的事，对方什么时候回复你不影响你当前的操作。

---


Linux启动流程分为5个阶段：
BIOS阶段：硬件自检，加载MBR中的引导程序
GRUB阶段：显示启动菜单，加载内核和initramfs
内核阶段：内核初始化，检测硬件，挂载根文件系统
Init阶段：启动init进程(PID=1)，读取配置文件，启动系统服务
登录阶段：启动登录服务，用户输入密码登录系统

init或systemd
 "init或systemd是Linux启动后第一个用户空间进程（PID=1），负责启动和管理所有系统服务，是整个系统的'总管家'。

13.比如说你要去分析日志的话，我有我有一长串的日志。就比如说你用nginx打印出来的，然后你怎么样去分析中间某一段，我把它截取出来了，我说用户ip。或者优化IP的聚集性，该怎么分析？
分析nginx日志的用户IP，可以用awk提取IP字段，再用sort和uniq统计IP出现次数，分析IP的聚集性。比如：awk '{print $1}' access.log | sort | uniq -c | sort -nr。


## 挂载
```bash
lsblk → mkdir /mnt/usb → mount /dev/sdb1 /mnt/usb → umount /mnt/usb
```


fdisk

**主要作用：**
- 查看磁盘分区表（显示磁盘和分区信息）
- 新建分区（primary/extended）
- 删除分区
- 修改分区类型
- 激活/禁用分区
- 写入分区表

---

## Linux划分新分区操作流程

> **小结：**
> 1. fdisk -l 查看磁盘
> 2. fdisk /dev/vdb 进入分区工具
> 3. n 新建分区，w 保存
> 4. partprobe 让系统识别新分区
> 5. mkfs.ext4 /dev/vdb1 格式化
> 6. mount /dev/vdb1 /mnt/data 挂载
> 7. /etc/fstab 设置自动挂载

死锁产生原因:
1. 死锁产生的原因（四个必要条件）
1.1 互斥条件
资源不能被多个进程同时使用，比如打印机、数据库连接等
1.2 请求与保持条件
进程已经占有了某些资源，又请求其他资源，但请求被阻塞时，不释放已占有的资源
1.3 不剥夺条件
进程占有的资源不能被其他进程强行剥夺，只能由进程主动释放
1.4 循环等待条件
存在一个进程等待链，形成循环等待
2. 死锁解决方案
2.1 预防死锁
破坏互斥条件：有些资源可以共享使用
破坏请求与保持条件：一次性申请所有需要的资源
破坏不剥夺条件：允许强制剥夺资源
破坏循环等待条件：给资源编号，按顺序申请
2.2 避免死锁
银行家算法：系统在分配资源前，先检查是否会导致死锁
资源分配图算法：检测是否存在循环等待
2.3 检测死锁
定期检测系统中是否存在死锁
如果检测到死锁，采取恢复措施
2.4 恢复死锁
进程终止：终止一个或多个死锁进程
资源剥夺：从某个进程剥夺资源，分配给其他进程

如何实现高可用性和灾难恢复？
答案: 实现高可用性和灾难恢复通常涉及在多个数据中心或地理位置部署应用和数据的副本，使用负载均衡器分散流量，以及定期备份数据和自动故障转移机制。

linux怎么看当前时间
date

## linux中怎么设置定时任务

### 方法一：编辑crontab
```bash
crontab -e
# 在编辑器中添加定时任务
20 18 2 8 * ./hello.sh
```

### 方法二：直接添加
```bash
echo "20 18 2 8 * ./hello.sh" | crontab -
```


如果要你设计一个自动化运维平台，主要功能是方便用户直接编写各类语言脚本，到相关服务器上运行，你会怎么设计，说一下设计架构。
设置一个前端web，用户在上面需要进行登陆操作 做权限控制，然后上面可以选择想部署的服务器，以及编写脚本，在提交请求后。会由后端服务器对用户进行鉴权，同时我们的脚本使用docker沙箱形式部署，针对不同用户创建不同的权限的沙箱。最后设置个数据库，记录用户提交的脚本以及用户id，用于做 操作人的追溯。


备份脚本怎么写的，备份需要注意些什么



30.如果说让你设计一个支持高并发的系统，你从这从怎么说呢？就你怎么设计，就是从就整个系统都交给你，你从前到后，就是说从开始的一些是可能是包括像刚才说的CDN，就是这种公司外部的资源来到公司内部的底层，你这里边你都会用哪些组件，要用他们的哪些特性。然后对然后最好每一步都要考虑一下有关它的扩展性这一块，就是不止要支持高并发，同时还要考虑一下扩展性。
1. 前端层 - 静态资源加速：
CDN：把静态资源（图片、CSS、JS）放到CDN，就近访问，减少带宽压力
特性：缓存、就近访问、负载均衡
扩展性：CDN节点可以无限扩展，按需增加节点
2. 接入层 - 负载均衡：
Nginx/LVS：做七层和四层负载均衡
特性：健康检查、会话保持、限流熔断
扩展性：可以水平扩展多个负载均衡器，用Keepalived做高可用
3. 应用层 - 业务处理：
微服务架构：按业务拆分服务，比如用户服务、订单服务、商品服务
特性：服务注册发现、负载均衡、熔断降级
扩展性：每个服务可以独立扩容，根据业务压力调整
4. 缓存层 - 数据加速：
Redis集群：缓存热点数据，减轻数据库压力
特性：内存存储、丰富数据结构、持久化
扩展性：Redis Cluster支持水平扩展，可以增加节点
5. 消息队列 - 异步处理：
Kafka/RabbitMQ：处理异步任务，比如订单通知、日志收集
特性：解耦、削峰填谷、可靠性
扩展性：可以增加分区和消费者，提高处理能力
6. 数据库层 - 数据存储：
读写分离：主库写，从库读，分散压力
分库分表：按业务或数据量拆分，提高并发能力
特性：数据一致性、事务处理
扩展性：可以增加从库、分片，水平扩展
7. 监控层 - 系统监控：
Prometheus + Grafana：监控系统性能、业务指标
特性：实时监控、告警、可视化
扩展性：可以增加监控节点，支持大规模集群

33.然后这个并发因为你刚才也有说到，用这个用队列去走一步，然后让他可以去减小这个实时并发的压力。如果说队列要被写爆了，对，队列如果要被写爆了，那你要用什么手段或者是建立什么样的能力，然后去防止整个系统被压力压垮、压崩溃、压雪崩
防护策略：
1. 限流保护：
生产者限流：在生产者端设置限流，比如每秒最多发送1000条消息
实现方式：用令牌桶、漏桶算法，或者直接限制QPS
效果：防止消息产生过快，给消费者处理时间
2. 熔断降级：
熔断机制：当队列堆积超过阈值时，直接拒绝新消息
降级策略：比如电商下单时，如果队列满了，可以降级为同步处理，或者直接提示用户"系统繁忙，请稍后重试"
实现：监控队列长度，超过阈值就触发熔断
3. 动态扩容：
消费者扩容：根据队列长度动态增加消费者实例
队列扩容：增加队列分区，提高并发处理能力
实现：用K8S的HPA，根据队列长度自动扩容
4. 消息优先级：
优先级队列：重要消息优先处理，比如支付消息优先级高于日志消息
死信队列：处理失败的消息放到死信队列，避免影响正常消息
实现：RabbitMQ支持优先级队列，Kafka可以设置不同Topic
5. 监控告警：
实时监控：监控队列长度、消费速度、延迟等指标
告警机制：队列堆积超过阈值时立即告警
可视化：用Grafana展示队列状态
6. 应急处理：
消息丢弃：极端情况下，可以丢弃非关键消息
批量处理：消费者批量处理消息，提高效率
异步处理：把消息处理改为异步，减少阻塞
实际应用：
比如电商秒杀场景：
限流：每秒最多1000个订单进入队列
监控：队列长度超过10000时告警
扩容：自动增加订单处理服务实例
降级：队列满时，新订单直接提示"请稍后重试"