## 网络

TCP是面向字节的协议，UDP是面向什么的协议
面向报文

为什么说UDP是面向报文的协议
通过UDP协议发送数据时，操作系统不会对用户信息进行拆分，对用户信息添加udp头后就直接发给网络层了，每个UDP报文都是一个用户信息边界

如何解决粘包：
1. 选择固定长度的信息，但是这种形式因为不灵活，所以使用较少
2. 使用特定符号作为分隔符，也就是作为边界，但这种形式需要注意原信息中有没有该特殊符号，若有则需要进行转义

TCP每次连接的初始化序号为什么都要不一样
主要是为了防止在特殊情况下，历史报文被下一次连接接收。虽然历史报文在四次挥手中，理论上会因为time_wait时间丢失，但是存在极限情况。比如说，服务器与客户端建立连接，客户端阻塞后重发数据，期间服务器重启，连接断开，服务器接收到数据后会进行重连。而假设重连后原来阻塞的数据到达服务器，则会导致数据混乱

初始化序列号是纯随机的吗？
是动态生成的，随着时间变化，这也是为什么不同的初始化序列号不同可以防止旧有数据干扰新连接，因为它的序列号，大概率在新连接服务器端期望接收序列号之外

为什么网络要分层
使得各层之间互相独立，每层只关注当前层的问题，提高灵活性扩展性

假设url发生了重定向，那么在负载均衡器的环境下，前端的url会发生变化吗
分为两种情况，一种是透明代理，这种情况下重定向的url会改变客户端的url，同时，假若是301也就是临时资源迁移，那么对应的重定向url不会被缓存，但是假若是302，也就是永久迁移，那么对应的重定向url会被浏览器缓存
第二种是重定向拦截，这种负载均衡会直接将流量重定向到对应的url，客户端url不变

如果说重定向被浏览器缓存了，那么浏览器访问A url的时候，实际上是被缓存引导往B url发送流量了吗？
对的

现在主流的web协议都是HTTPS了，少数环境还会用HTTP，那么HTTP目前的哪些使用场景仍在使用？
运行在对性能要求较高，对资源花销敏感的安全环境。比如说内网，比如说测试环境等等

QUIC协议听说过吗？说说看
QUIC协议是HTTP3协议的基础。它基于UDP协议完成，同时兼顾TLS的加密功能，多个HTTP请求可以同时传输

计算机网络的拥塞控制和流量控制的区别
拥塞控制指的是网络上的拥塞控制，如减少丢包，常见方法有拥塞避免
流量控制则是根据接收方能接收的流量来发送，常见方法有滑动窗口

广播和单播的区别？
广播：一对多发送数据，不指定接收方
单播：一对一发送信息，指定接收方

路由器和交换机分别在哪一层？
路由器：网络层
交换机：数据链路层

301跟302的区别
301永久重定向 302临时重定向

1 RTT代表什么
本端发送请求到对方响应并传回的时间

应用层有哪些协议
http/https，DNS,SSH，SMTP

传输层有哪些常见的协议？
TCP,UDP

网络层有哪些协议
ARP（网络与数据链路层之间），BGP，IP,ICMP,NAT

HTTP是无状态的，为什么能记住用户的登陆状态
主要是通过session+cookie的方式实现的。当用户登录时，服务器会创建一个session，并保存到本地，同时发送一份给客户端，客户端保存sessionid为cookie，当下次向服务器请求时，客户端会顺路把带sessionID的cookie发过去，服务器从cookie拿出sessionID，找到之前保存的serssion，找到对应的状态

URI和URL的区别
URI是统一资源标识符，相当于唯一表示一个资源的方式
URL是统一资源定位符，表示获取该资源的路径

什么是 WebSocket?
websocket是一种全双工通信协议，即客户端和服务器端能同时接收或发送数据，是一种一次握手就能保持长时间连接的方式

websocket与短轮询长轮询的区别
短轮询：客户端每隔一段时间往服务区段发送询问是否有新数据，若有则发送。优点是简单，缺点是实时性一般，而且长期反复建立销毁连接
长轮询：客户端发起请求后，，若服务端无新数据，则保持等待，直到服务端有新数据，传回客户端，随后客户端快速发起新的请求。优点：实时性强，缺点是长期占用连接
websocket:一次握手之后持久连接，双向发送数据。优点是实时性强，缺点是实现麻烦

syn包什么时候会被丢弃
1. 开启快速回收内核参数（tcp连接中的一个内核参数，目前已废弃），在nat环境下会丢syn包
2. tcp连接队列满了

如何优化TCP三次握手性能
对于客户端来说，可以根据网络繁忙程度动态调整超时重传时间，减少重传时间以将问题更快暴露
对于服务端来说，同样可以根据网络繁忙程度动态调整服务器端在第二次握手中，SYN+ACK的重传时间
对于绕过三次握手来说，可以开启 fast open来降低HTTP请求时间

如何优化TCP四次挥手性能

DNS是基于什么协议的
总结来说，DNS默认用UDP协议的53端口进行通信，遇到大数据包或特殊需求时会自动切换到TCP协议的53端口。现在主流的加密DNS方案还会用到HTTPS或TLS等协议，进一步提升安全性。

HTTP长连接短连接，优缺点, 状态码有哪些
 "HTTP长连接是一次TCP连接传输多个HTTP请求，短连接是每个请求都建立新连接。长连接优点是减少连接开销、提高效率，缺点是占用资源、需要保活；短连接优点是简单，缺点是开销大。

TCPIP协议解决什么问题
“TCP/IP协议主要解决了不同计算机和网络之间互联互通、数据可靠传输、寻址路由、多应用并发等问题，是互联网通信的基础协议。”

什么ip地址
ip地址是每个连接入互联网的设备被分配的唯一地址标识符

什么是ip地址过滤
ip地址过滤是阻止某个或者某个范围内的ip地址访问，是一种互联网安全措施

ip和mac的关系
数据先靠IP找到大致位置，再靠MAC精确投递到设备。
MAC 是我们网卡的物理地址，用于局域网内通信，IP地址是逻辑地址，用于网络层寻址。IP负责定位主机，MAC负责实际传递数据。两者通过ARP协议关联起来，实现数据从一台主机精确送到另一台主机的网卡上。”

https和http的区别
https 相较于http实现了 数据加密，即使截获了也看不懂。同时https常用443端口而http为80，同时https需要TLS/SSL证书恒明网站身份

网络地址跟广播地址的
假设网段为192.168.1.0/24 那么网络地址就是192.168.1.0，广播地址是192.168.1.255


怎么优化http1请求
1. 启用缓存，将未过期的响应数据缓存到客户端本地服务器，防止一样的数据请求多次
2. 减少http请求数，将重定向交给代理服务器处理。同时可以将多个小资源的http请求合并为一个大资源的http请求，避免多次请求。按需请求资源，当客户下滑时才进行请求

怎么优化https请求
1. 硬件上，因为tttps是计算密集型，所以需要选用更好的cpu
2. 协议上，使用ECDHE算法，而非RSA算法
3. 会话服用，允许复用没过期密钥

http2相较于http1改进了什么
1. https兼容http1.1
2. HTTP2进行了帧头压缩
3. https支持多路复用，允许并发stream
4. 支持 服务器主动推送资源到客户端

http2的缺陷是什么
HTTP2仍是基于tcp协议，而tcp协议需要保证数据是完整而且连续的。哪怕说我们发送了三个http请求，tcp也会将这些请求按顺序传输，同时如果请求中存在数据超时或者丢失，哪怕其他两个请求已经到达，也无法处理

http几代之间的差异
1. HTTP/1.0
特点：每个请求都要建立新的TCP连接，用完就断开
问题：效率低，延迟高，资源浪费
类比：每次打电话都要重新拨号，说完就挂
2. HTTP/1.1
改进：引入持久连接（Keep-Alive），一个TCP连接可以处理多个请求
新增：分块传输、缓存机制、Host头等
问题：队头阻塞（Head-of-line blocking），后面的请求要等前面的完成
类比：一条电话线可以连续通话，但必须按顺序说
3. HTTP/2
核心：多路复用（Multiplexing），一个TCP连接同时处理多个请求
新增：服务器推送、头部压缩、二进制传输
优势：解决了队头阻塞，性能大幅提升
类比：一条电话线可以同时进行多个对话
4. HTTP/3
底层：基于UDP的QUIC协议，而不是TCP
优势：解决了TCP层面的队头阻塞，连接建立更快
特点：0-RTT连接、更好的丢包恢复、多路复用
类比：用更快的快递方式，即使丢包也能快速恢复

rpc是什么
RPC是通过网络通信和协议封装来实现远程调用的方式。当你在本地调用一个RPC函数时，相当于调用代理服务器，它会将调用请求发送到远程服务器

rpc

2xx、4xx、5xx系列分别代表什么？
2xx成功
3xx重定向
4xx客户端有问题
5xx服务器端有问题
在SRE工作中，你会重点监控哪些状态码？为什么？
重点关注4xx，5xx，因为它们反应了连接的问题
如果你发现4xx错误突然增加，你会怎么排查？
首先会连到nginx上，查看被refued或者timeout的请求。分析是不是客户端的版本有问题。
或者是api更换了位置，或者是权限配置错误，客户端没权限访问服务器。
5xx错误和4xx错误在排查思路上有什么不同？
5xx更多的是服务器内部本身的问题，或者是网关，以及负载均衡，数据库上的问题。
4xx更多聚焦于客户端本身，比如被禁用了，比如api更换位置了,但是nginx配置没更新上。


给出ip地址，问有多少个子网地址可用
192.168.1.0/24

                                          8      7    6    5    4    3   2   1
                                          128   64   32   16   8   4   2   1

                                          192.168.1.00000001/24
                                          有2**8次方-2，除去网络和广播地址，254个可用ip地址
dns过程
2. DNS解析的全过程
1）浏览器发起请求
你在浏览器输入网址，浏览器先查本地有没有缓存的IP地址。
2）本地DNS缓存
如果本地有缓存（比如你刚访问过），直接用缓存的IP，不用再查。
3）操作系统DNS缓存
本地没有，再问操作系统的DNS缓存，有就用，没有继续查。
4）找本地DNS服务器（通常是运营商的DNS）
本地都没有，操作系统会把请求发给配置好的DNS服务器（比如8.8.8.8或者运营商的DNS）。
5）递归查询
本地DNS服务器如果也没有，就会帮你去“打电话”问外面的DNS服务器，过程如下：
根DNS服务器：先问根服务器，“.com”域名管谁？”
顶级域DNS服务器（TLD）：根服务器告诉你去找.com的服务器
权威DNS服务器：.com服务器再告诉你，baidu.com归哪个权威DNS管
最终返回IP：权威DNS服务器告诉你www.baidu.com的真实IP
6）返回结果
本地DNS服务器拿到IP后，先缓存起来，然后把IP返回给你的电脑，电脑再把IP交给浏览器，浏览器就能访问网站了。
4. 面试口语表达
> “DNS解析过程就是把域名翻译成IP的过程，先查本地缓存，再问本地DNS服务器，如果还没有就递归去问根、顶级域、权威DNS，最后拿到IP地址返回给客户端。”

 请解释一下TCP三次握手的具体过程，以及为什么需要三次握手而不是两次？如果第三次握手丢失会发生什么？
1.客户端向服务器发送SYN请求。
2.服务器向客户端发送AYN加ACK
3.客户端向服务器发送ACK,连接建立
不是两次握手主要是怕超时的请求重新被发送到服务器端.假设客户端延迟很高,发送一次请求之后超时,再重新进行发送后建立了连接,而此时服务端接受到了那个超时的请求,就会导致简历错误的请求
第三次握手如果丢失的话,客户端会认为连接已经建立,进入ESTABLISHED(连接已建立)状态而服务端认为连接没建立,进入半连接状态,无法正常传输数据.

TCP三次握手和四次挥手你肯定知道，但我想问个实际的：
在生产环境中，你发现服务器上有大量的TIME_WAIT状态的连接，这会导致什么问题？应该如何解决？
1.这个可能导致我们的tcp连接端口耗尽，旧的连接一直占用，新连接无法正常链接上来导致超时。同时太多的连接会占用内存。
2.解决方法是1.调整内核参数，允许端口复用。2.调整time_wait时间，将其调段短。3.尽量使用长连接，让其可以发送多个http请求。同时也可以考虑扩大连接池以及设置超时时间。
也可以设置负载均衡，把请求发送到不同的服务器来进行分流。

- **OSI七层**: 物理→数据链路→网络→传输→会话→表示→应用
- **端口**: HTTP(80) HTTPS(443) SSH(22) FTP(21) DNS(53)
- **TCP**: 三次握手建连，四次挥手断连，TIME_WAIT(2MSL)

OSI七层模型及每层作用
物理层（Physical Layer）
作用：负责比特流的物理传输（0和1的电信号/光信号），与网线、光纤、无线电波等物理介质打交道。
典型设备：网线、集线器、光纤、网卡的物理部分。
数据链路层（Data Link Layer）
作用：在物理层之上，负责点到点的数据帧传输、差错检测与纠正、MAC寻址。
典型协议/技术：以太网（Ethernet）、PPP、MAC地址、交换机。
网络层（Network Layer）
作用：负责数据包的路由和转发，实现不同网络之间的通信（寻址和路由选择）。
典型协议/设备：IP协议、ICMP、ARP、路由器。
传输层（Transport Layer）
作用：实现端到端的可靠/不可靠数据传输，流量控制、差错校验、分段重组。
典型协议：TCP（可靠）、UDP（不可靠）。
会话层（Session Layer）
作用：建立、管理和终止会话（会话管理、同步、检查点恢复）。
典型应用：RPC、SQL会话、NetBIOS。
表示层（Presentation Layer）
作用：数据格式转换、加密解密、压缩解压（让不同系统能理解数据）。
典型应用：SSL/TLS加密、JPEG、MPEG、ASCII/Unicode转换。
应用层（Application Layer）
作用：为用户提供网络服务和应用接口，直接与用户交互。
典型协议/应用：HTTP、FTP、SMTP、DNS、Telnet、SSH、POP3等。

网关跟路由器的区别
网关作为逻辑上的虚拟概念，一般是网络的出入口
路由器负责实打实的ip端对端寻址，在一般家庭网络中，路由器就是网关

四层模型是什么

**四层模型**通常指的是**TCP/IP四层网络模型**，也叫做**TCP/IP协议栈**，是计算机网络通信的经典分层架构之一。它将网络通信过程分为四个层次，每一层负责不同的功能。

---

### TCP/IP四层模型结构

1. **应用层（Application Layer）**
   - 功能：为用户的应用程序提供网络服务。
   - 常见协议：HTTP、FTP、SMTP、DNS、SSH、Telnet等。
   - 举例：你用浏览器访问网页，浏览器就是应用层。

2. **传输层（Transport Layer）**
   - 功能：实现端到端的数据传输和可靠性控制。
   - 常见协议：TCP（面向连接，可靠）、UDP（无连接，不可靠）。
   - 举例：网页数据通过TCP协议可靠传输。

3. **网络层（Internet Layer）**
   - 功能：负责数据包的路由和转发，实现不同主机/网络之间的通信。
   - 常见协议：IP（Internet Protocol）、ICMP、ARP等。
   - 举例：IP协议负责把数据包从一台主机送到另一台主机。

4. **网络接口层/链路层（Network Access/Link Layer）**
   - 功能：负责物理传输、数据帧的封装与解封装，直接与硬件打交道。
   - 常见协议：以太网（Ethernet）、Wi-Fi、PPP等。
   - 举例：网卡驱动、物理信号传输。

---
说一下负载均衡，负载均衡有啥作用
 负载均衡（Load Balancing）是一种将用户请求或网络流量分发到多台服务器上的技术，目的是提升系统的并发处理能力、保证高可用性和服务的稳定性。
 作用总结
提升系统性能和吞吐量
多台服务器共同分担压力，单台服务器不会成为瓶颈。
高可用性和容错性
某台服务器宕机时，流量自动切换到其他健康节点，保证服务不中断。
弹性扩展
可以根据业务量动态增加或减少后端服务器，实现弹性伸缩。
优化用户体验
通过就近分发、健康检查等机制，减少响应延迟，提高访问速度。
简化运维和升级
可以无感知地下线某台服务器做维护或升级，用户无感知。

了解哪些负载均衡软件，都说一下
nginx,HAProxy, 云厂商提供的负载均衡 CLB等

四层负载均衡了解吗，四层负载均衡的工作原理，有哪些负载均衡软件是基于四层负载均衡的
四层负载均衡（Layer 4 Load Balancing）是基于OSI模型的传输层（主要是TCP/UDP协议）进行流量分发的负载均衡方式。它根据客户端的IP地址、端口、协议类型等信息，将请求转发到后端服务器。
四层负载均衡器在收到客户端请求时，不会解析应用层数据（如HTTP头），而是直接根据TCP/UDP的（源IP、源端口、目标IP、目标端口、协议）进行转发。
常见的有Nginx和HAProxy以及云厂商的负载均衡

四层和七层nginx的负载均衡都有哪些
四层负载均衡：
Nginx的四层负载均衡是基于TCP/UDP协议，使用stream模块。它工作在传输层，只能根据IP和端口进行负载均衡，不能解析HTTP协议。配置相对简单，性能比较高，适合对性能要求高的场景。
七层负载均衡：
Nginx的七层负载均衡是基于HTTP协议，使用http模块。它工作在应用层，可以解析HTTP请求，根据URL、请求头、Cookie等信息做更精细的负载均衡。功能更强大，但性能相对较低。

普通哈希和一致性哈希的区别
普通哈希实现简单，但扩展性差，服务器变化时数据迁移量大；一致性哈希扩展性好，数据迁移量小，但实现相对复杂。现代分布式系统（如Redis、分布式存储等）普遍采用一致性哈希，因为它能很好地支持动态扩缩容的需求。

---

> 四层模型指的是TCP/IP协议栈，包括应用层、传输层、网络层和网络接口层。它分别负责应用服务、端到端传输、路由寻址和物理传输，是现代网络通信的基础分层架构。

用过抓包工具吗? 想查看我们访问某个域名时流量做了哪些跳转应该怎么做


什么是 BGP 协议？
BGP协议是边界网关协议，它是互联网里的GPS导航系统。互联网由多个大型独立的网络组成，每个网络被称为一个自治系统，BGP在他们直接进行互相宣告以及路由学习。当路由器拿到某个目标ip时，会访问BGP，然后拿到最优路由路径。

一个Web服务器的负载突然升高，你怀疑是有大量新连接涌入。你会使用哪些Linux命令来快速查看当前服务器的网络连接状态？你应该重点关注哪些连接状态？
使用ss 来查看当前服务器的网络连接状态。需要关注的有以下几种状态
1.close_wait，这个是第二次挥手后的服务器状态，出现这个的原因可能是程序没有正常断开连接。
2.time_wait状态，这种状态可能是我们服务器主动断开了连接，但是因为大量的高并发短连接占用了tcp端口导致的大量time_wait。
3. syn_rev 状态，这种状态是第三次握手时服务器的状态，服务器等待客户端发送第三次握手请求来正式建立链接，出现大量这种状态可能是被ddos攻击了，ddos服务器只发送SYN请求，消耗服务器的半连接队列

tcp报文的序列号和确认号机制
客户端和服务端都随机取一个初序列号，当客户端初序列号为1000，发送500个字节的报文时，下一个初序列号就是1500
确认报机制是为了防止因网络原因导致数据接收紊乱，当服务段接收到1500的序列号，它会返回ack=1500，表示前1499个数据接收到了，希望下一段报文从1500开始。而若此时服务端接收下一个报文为2000，则会将其缓存，等待1500序列号的重传。

二层网络中通信的具体过程是什么
二层模型一般是同局域网内的进行数据发送的过程。如果A服务器要往B服务器发送信息，那他首先会往局域网内发送ARP广播请求，表示“xxxx ip地址是谁的”，交换机接收到这个广播之后，会往除源端口外的所有端口都进行转发。只有B会相应这个请求，向A服务器发送一个ARP单播相应，内有它的mac地址，经过交换机作为中间人。a拿到mac地址后，会将b的ip与mac地址一起封装成帧，交换机接收到这个数据后，读取帧头的mac地址，查看mac地址表，找到b路由器连接的端口，精准发送到b

ARP协议是什么
ARP协议是数据链路层中 将ip地址转化为MAC地址的一种寻址协议

描述一下tcp报文头
tcp报文头一般有20个字节。包含有源端口目的端口，序列号确认号，窗口，状态位

tcp和linux可用端口数分别有多少
65535

你提到了端口复用，Linux内核中有两个常见的相关参数：tcp_tw_reuse 和 tcp_tw_recycle。你能解释一下它们分别是如何工作的，以及为什么在现代的Linux内核中，tcp_tw_recycle 被认为是不安全的并被废弃了？
端口复用是允许将time_wait状态下的端口用于新的出站连接。
快速回收：快速回收出站入站的连接。工作机制是对比ip的时间戳，对于同一个ip，会对比时间戳是否更新，若为旧的，则丢弃。废弃的原因是因为在NAT环境下，多个机器通过相同的公网ip访问，而时间戳各不相同，可能会有机器的连接因此被丢弃

虚拟机有几种网络模式
1. nat模式，虚拟机会被分配一个虚拟的NAT设备和DHCP服务器，为虚拟机分配一个私网ip地址，宿主机像一个路由器。虚拟机可以访问外部网络，但是外部网络不可以直接访问虚拟机，需要宿主机配置端口转发
2. bridge模式，虚拟机的虚拟网卡连接到物理网络上，会被路由器分配一个和宿主机一样的独立的ip
3. host-only模式，只可以跟宿主机互相通信

301跟302的区别
301是永久重定向，表示资源已经转移到新的url，浏览器会缓存这个重定向
302表示临时重定向，资源暂时转移到另一个url，下次访问时浏览器仍将请求往这边转发

---
 
## 1. 常用抓包工具有哪些？
- **Wireshark**（图形界面，功能最强大，支持协议解析和过滤）
- **tcpdump**（命令行，轻量级，适合服务器环境）

---

## 2. 如何用抓包工具分析访问域名时的流量跳转？

### （1）明确目标：
你要分析"访问某个域名时，流量做了哪些跳转"，比如DNS解析、HTTP 301/302重定向、HTTPS握手、CDN跳转等。

### （2）操作步骤：

#### A. 用Wireshark举例（最常用）
1. 启动Wireshark，选择正确的网卡接口开始抓包。
2. 设置过滤条件（比如只看目标域名相关流量）：
   - 过滤HTTP/HTTPS流量：`http` 或 `tcp.port == 80 || tcp.port == 443`
   - 过滤DNS流量：`dns`
   - 过滤目标IP：`ip.addr == 目标IP`
3. 在浏览器访问目标域名（如 www.example.com）。
4. 观察抓到的包：
   - 先看DNS请求，确定域名解析到哪个IP。
   - 再看TCP三次握手、SSL/TLS握手（HTTPS）。
   - 关注HTTP请求和响应，特别是`Location`字段（301/302重定向）。
   - 跟踪整个会话，分析是否有多次跳转（如www跳到m、http跳到https、CDN跳转等）。
   - 可以用"Follow TCP Stream"功能，串联起一次完整的会话过程。

---

#### B. 用tcpdump抓包

**步骤一：查域名对应ip**
```bash
nslookup www.baidu.com
```

**步骤二：用tcpdump抓包**
```bash
sudo tcpdump -i eth0 host 93.184.216.34 -w output.pcap
```
- `-i eth0`：指定网卡（实际环境可能是ens33、enp0s3等）。
- `host 93.184.216.34`：只抓和目标IP相关的包。
- `-w output.pcap`：把抓到的包保存到文件，便于后续用Wireshark分析。

**步骤三：分析抓包结果**
- 用Wireshark打开output.pcap文件。
- 过滤HTTP/HTTPS流量，查看是否有301/302重定向（Location字段）。
- 过滤DNS流量，查看域名解析过程。
- 跟踪TCP连接、TLS握手、CDN跳转等。

一个请求用户反馈http时间久，怎么解决
1. 首先我们本地访问 这个http，看是不是用户侧的网络问题，其次使用ping命令看报文的返回时间，用curl命令 查看返回报文的相应状态以及状态码
2. 再次连接到服务器，检查磁盘或内存利用率，看是不是利用率过高，清除缓存以及日志，检查有没有大量进程锁导致内存利用率过高，系统频繁交换内存swap导致卡顿，协调业务看是不是业务量增大导致需要更高的资源分配，进行资源扩充，同时在业务低峰期重启释放更多内存
3. 检查cpu利用率，看有没有太多僵尸进程或者进程锁，检查是不是因为 内存频繁交换导致cpu利用率飙升。同样也需要跟业务协调
4, 如果服务有链接数据库,还需要检查慢查询日志,使用mysqldumpslow分析慢查询日志,进行索引优化/查询语句的优化，同时检查redis连接池，看是不是因为业务量增大导致连接池满了，协调业务看需不需要扩充连接池/能不能减少长链接
4. 最后检查我们的告警程序，理论上来说不应该会有这些情况发生，看看是不是告警没触发或者没配置相关告警规则

如果有用户反馈说小红书某个功能很慢，你怎么排查，说一下从客户端到服务端全链路，具体到网络通信细节
先从客户端来说，我会先在自己本地去访问这个功能，看看是不是真的很慢，排除用户侧网络的问题。
如果确实真的很慢，会nslookup 域名，看看我们的DNS解析是否正常，会向部署了该服务的服务器发送ping请求，查看是不是因为网络原因导致卡顿。使用curl命令分析HTTP请求的响应时间和状态码。
再连接到服务器，查看服务器的内存，磁盘使用情况，看看是不是打满了。
若打满则需要 和业务协调，删除一些日志文件和临时缓存。跟业务沟通是不是业务量增大导致系统资源配置不够，不够则扩充同时在业务量低谷期重启释放更多资源。
如果不是内存，磁盘的问题，那就看看CPU，观察是不是CPU利用率过高，先调整配置扩大CPU配额，再同上跟业务沟通是否需要扩容，同时检查是否有太多死锁/因为内存不足导致频繁IO使得CPU利用率过高。
最后是进行复盘，理论上不应该会有服务器 资源利用率过高导致影响功能的情况，所以需要我们 看看告警是不是没触发，告警规则是否漏了或者有异常。
检查我们的应用错误日志，看看是不是业务代码报错，但因为设置了超时机制，导致错误未被正常抛出，选择超时后进行运行，同时检查我们功能相关的慢查询是不是太多了。
如果功能连接了redis，需要同步排查是不是redis连接池满了，看业务那边是不是新增业务导致redis连接池不够，需要及时扩充，或者跟业务协调减少长链接

说说curl -v -i的返回信息


调用第三方接口超时如何排查
1. 首先是去另一台主机curl第三方接口看看返回值是不是200
2. 再次是tcpdump抓取一下，我们ping 部署该接口的主机能不能联通
2. 再次是nsdumpup检查DNS解析正不正常
4. curl -i- v检查ip跳转情况
3. 连到服务器上查看防火墙配置，以及安全组有没有设置成允许外来流量从nginx监控的端口 进入
3. 查看负载均衡，看该接口的监控地址正不正确，是不是设置成了本地回环地址而不是0.0.0.0，同时检查它的转发地址和端口，lsof查看这个端口有没有正常开放
4. 下一步就要检查服务本身了，如果是用docker起的 服务，那需要检查docker的状态，是不是正常启动的，logs查看镜像日志。
5. 如果这个接口对接有mysql数据库或者redis连接池，得进行慢查询日志的采集以及优化，同时得检查redis连接池，看是不是连接池满了

你说先用curl检查返回值，那如果curl返回200但实际业务还是超时，你觉得可能是什么原因？
1. 返回两百，至少可以说明我们负载均衡和dns解析都是正常的，所以可能得从部署了服务的服务器上面去看看
2. 检查服务器的cpu，内存等利用率，看是不是业务量增大导致的资源不够，IO进程等待导致超时
3. 如果服务连接有redis，mysql等数据库，那就还是跟上面一样的，慢查询排查，redis连接池检查，业务评估是否需要扩大连接池，以及进行慢查询优化和尽量减少长链接的使用

面试官：你说"从部署了服务的服务器上面去看看"，那你怎么确定是哪台服务器？如果第三方接口有多个实例，你怎么定位到具体哪台服务器有问题？
确实，我们域名解析，解析到的应该是部署了负载均衡服务的地址，那么我们首先得连接到该地址上面去，通过nginx日志分析
# 查看nginx访问日志，分析响应时间
tail -f /var/log/nginx/access.log | grep "超时特征"

# 分析哪些后端服务器响应慢
awk '{if($10>5) print $1, $10}' /var/log/nginx/access.log

 如果一个简单的服务暴露了端口，在服务器外访问不到，你要怎么进行排查，没有连mysql，redis，只是一个简单的服务
1. 服务未启动。ps aux查看进程状态是否正常
2. 检查端口监听情况， lsof -i：port
3. 服务器绑定错误，只绑定到本地回环地址，nginx监听错误，被设置成了127.0.0.1而非0.0.0.0
3. 防火墙阻止,检查防火墙设置，systemctl status firewalld
4. 云服务器安全组



在浏览器输入网址到页面展示内容，中间发生了什么
在浏览器输入网址到页面展示内容，中间主要发生了以下步骤：
> 1. 浏览器检查本地DNS缓存，若无则向本地DNS服务器请求解析域名。
> 2. 本地DNS服务器若无缓存，会递归查询（根服务器→顶级域服务器→权威服务器），最终获得目标IP。
> 3. 浏览器与目标IP建立TCP连接（如HTTPS还需TLS握手）。
> 4. 浏览器发送HTTP请求，服务器返回网页内容。
> 5. 浏览器解析HTML，渲染页面，并根据需要继续请求CSS、JS、图片等资源，最终完整展示页面。

当你在Linux服务器上 ping 一个域名（比如 ping www.google.com）失败，但 ping 它的IP地址（比如 ping 8.8.8.8）却能成功，这通常是什么问题？你会如何排查？
这个我首先怀疑是DNS解析的问题。先ping它的ip地址查看报文的返回情况。再检查我们本地的/etc/hosts，看是不是我们强制配置了一个错误的，或者停用了的ip地址。再到/etc/resolv.conf检查是不是配置了错误的DNS服务器，再使用nslookup查看DNS的解析情况。最后是查看我们的防火墙或者云安全组，看是不是禁用了DNS服务器的UDP 53端口

常用的8.8.8.8DNS服务器地址，是真实的ip地址吗？
是又不是，它更多是一个逻辑地址。因为我们有个任播的技术，可以使得多个服务器共享一个ip地址，当我们发送DNS请求8.8.8.8时，路由器会自动帮我们连接到最近的google数据服务器。

## **TCP和UDP的区别**
> **TCP**：面向连接、可靠传输，保证数据顺序、无丢失，适合对可靠性要求高的场景。
>
> **UDP**：无连接、不保证可靠性，速度快、开销小，适合实时性要求高、能容忍丢包的场景。



TCP如何保证可靠性
第一个是确认机制，发送方发送数据后，接收方必须回复确认，告诉发送方收到了。如果发送方没收到确认，就会重传数据。
第二个是序列号，每个数据包都有序列号，接收方可以按顺序重组数据，如果发现丢包了，会要求重传。
第三个是超时重传，发送方发送数据后会启动定时器，如果超时还没收到确认，就认为数据丢了，会重新发送。
第四个是流量控制，接收方告诉发送方自己能接收多少数据，防止发送方发送太快，接收方处理不过来。
第五个是拥塞控制，当网络拥堵时，TCP会自动降低发送速度，避免网络更拥堵。"

TCP的拥塞控制采用的算法
"TCP的拥塞控制主要采用四个算法：慢启动、拥塞避免、快重传、快恢复。这四个算法配合使用，根据网络情况动态调整发送速度。
慢启动用于连接建立初期，快速探测网络容量。拥塞避免用于网络稳定时，避免网络拥堵。快重传和快恢复用于快速恢复，减少重传延迟。
这些算法通过拥塞窗口来控制发送速度，拥塞窗口越大，发送速度越快。算法会根据网络反馈动态调整拥塞窗口大小。"

TCP三次握手流程（ACK包（确认应答包），FIN包（用于主动关闭TCP连接））
第一次握手：客户端发送SYN包（SYN=1，Seq=x）到服务器，进入SYN_SEND状态。
第二次握手：服务器收到SYN后，回复SYN+ACK包（SYN=1，ACK=1，Seq=y，Ack=x+1），进入SYN_RECV状态。
第三次握手：客户端收到SYN+ACK后，回复ACK包（ACK=1，Seq=x+1，Ack=y+1），进入ESTABLISHED状态。服务器收到ACK后也进入ESTABLISHED状态，连接建立完成。
TCP四次挥手流程
第一次挥手：主动关闭方（通常是客户端）发送FIN包，表示没有数据要发送了。
第二次挥手：被动方（服务器）收到FIN后，回复ACK包，表示收到关闭请求。
第三次挥手：被动方处理完数据后，发送FIN包，表示可以关闭连接了。
第四次挥手：主动方收到FIN后，回复ACK包，进入TIME_WAIT状态，等待一段时间后彻底关闭连接。服务器收到ACK后立即关闭连接。
> TIME_WAIT的作用：确保最后一个ACK能被对方收到，防止"迟到的包"影响新连接。

TCP协议如何保证可靠传输？
1.序列号与确认应答：发送端会将数据划分为多个数据段，服务端接受之后会回发给一个ACK，表示我已经接受到了xx的数据，下次希望它从第x个编号开始发。当发送方收到错误的ACK之后，会根据序号的错乱情况进行重新排序。
2.三次握手，四次挥手机制，保证连接的可靠
3.超时重传机制，在发送请求后会有计时器进行超时控制，，避免数据段在网络中丢失导致数据丢失，重新发送数据
4.流量控制机制：使用滑动窗口，接收端告知发送端自己可以处理的最大数据，避免了发送过多导致的接收方阻塞。
5.拥塞控制机制：通过慢启动，拥塞避免，超时重传，快速重传机制避免因为网络或者发送数据过大导致阻塞，压垮整个网络


close_wait状态过多说明什么
说明可能程序并没有调用close()方法正确处理连接关闭,可能存在内存泄露的情况.

FIN_WAIT1状态过多：
说明大量的客户端发送到fin请求并没有被服务端相应返回ACK，可能存在网络波动或者丢包。

close wait和time wait它俩的区别在哪里？
CLOSE_WAIT :被动关闭方（收到FIN的一方）的状态,表示"我收到了对方的关闭请求，但我还没准备好关闭"
TIME_WAIT: 主动关闭方（发送FIN的一方）的状态,表示"我已经发送了关闭请求，等待确认"
特征	CLOSE_WAIT	TIME_WAIT
触发方	被动关闭方	主动关闭方
持续时间	程序处理时间	2MSL（60秒）
问题	程序bug导致堆积	占用端口资源
解决	修复程序逻辑	调整内核参数

那像这个去优化它的参数，调整内核的这个参数，你大概能说出来几个吗？就是针对time_wait规则优化这一块，内核参数。
"主要调整几个内核参数。第一个是tcp_tw_reuse，设置为1，允许重用TIME_WAIT连接，但前提是要启用tcp_timestamps。第二个是tcp_fin_timeout，控制FIN_WAIT_2的超时时间，默认60秒，可以缩短到30秒。第三个是tcp_max_tw_buckets，限制TIME_WAIT连接的最大数量，防止连接过多。"


滑动窗口的作用与原理
作用：实现TCP流量控制，保证发送方不会发送超过接收方缓冲区的数据量，防止接收方处理不过来导致丢包。
原理：接收方在ACK包中告知发送方自己的窗口大小（可接收的数据量），发送方根据窗口大小决定可以连续发送多少数据，无需每发一包都等待确认。窗口满了就暂停发送，窗口滑动后继续发送。

## HTTP状态码
- **2xx**: 200成功 201创建 204无内容
- **3xx**: 301永久重定向 302临时重定向 304未修改
- **4xx**: 400请求错误 401未授权 403禁止 404未找到
- **5xx**: 500内部错误 502网关错误 503不可用 504超时

阻塞控制算法：
在初始阶段，拥塞窗口会以2**n的形式进行指数型上升，当达到慢启动阈值后，会以+1的形式进拥塞窗口增加。
随着拥塞窗口不断上升，可能出现两种情况
A. 超时重传
当超时重传后，拥塞窗口会被设置为1，慢启动阈值设置为当时拥塞窗口的1/2，重新开始流程
B. 快速重传
当接收到三个相同ACK后，慢启动阈值会被设置为当前拥塞窗口的1/2,同时将拥塞窗口设置为慢启动阈值


面试官： 我看到你简历中提到做过监控平台，对Nginx应该比较熟悉。现在给你一个具体的生产场景：
我们公司有一个电商网站，使用Nginx做负载均衡，后端有3台应用服务器。最近发现用户反映网站访问很慢，有时候还会出现502错误。运维团队发现其中一台后端服务器CPU使用率很高，达到了95%。
问题： 作为SRE工程师，你会怎么排查这个问题？请详细说明你的排查思路和具体步骤。
1. 首先在自己本地机器nslookup扫一下域名，看DNS解析正不正常，再curl -v 域名查看跳转情况，最后是ping域名查看返回报文时间
2.连接到部署负载均衡的服务器，检查日志，看超时的连接情况。看是不是流量分发机制出现问题，权重设置不合理导致太多流量被发到那台CPU利用率高的后端服务器
3. 连接到那台后端服务器，top检查cpu利用率，同时free查看内存使用情况，看究竟是不是因为连接太多内存不足，频繁io使得服务器卡顿导致访问很慢这个并发问题。
5. df -hT检查存储，清缓存，流量低谷期重启
6. 重新设置nginx权重，将其他两台服务器的权重往上抬，让更多流量先往那两台服务器跑。如果服务器是云服务器，先紧急增加一下分配给这台服务器的资源
7.最后同步再检查一下数据库，看是不是连接太多导致查询增多，慢查询增多导致返回变慢，访问速度变慢，检查redis连接池会不会有满的情况发生，先扩大一下连接池。
8,对热点key进行缓存，减少打到数据库的情况，减轻数据库压力，防止再有连接增大使得数据库压力增大，服务卡顿的情况发生


问题1： 你说要检查Nginx日志看超时连接情况，具体要查看哪些日志文件？怎么看超时连接？能给我一个具体的命令示例吗？
一般来说是看error.log错误日志,连接超时一般是5xx的错误,或者connected fail,可以使用grep命令过滤出来超时相关错误.需要关注是不是集中在某个时间段
问题2： 你提到要重新设置Nginx权重，具体怎么修改？如果这台慢服务器完全不可用，你会怎么配置？
具体是在upstream模块处配置weight,把其他两台调高调成5,或者把这台调为1
在uostream模块处把这个服务器给down掉先
问题3： 你说要检查Redis连接池，怎么查看Redis连接池的使用情况？如果连接池满了，具体会有什么表现？
使用redis cli命令来检查现有连接,以及最大连接.连接池满了一般redis汇报错too many connection 然后会连接超时/链接被拒绝/响应时间会变长。连接池满了需要紧急扩充连接池，或者是在流量低谷期重启应用

面试官： 现在给你一个网络故障场景：
我们公司的一台服务器A，ping服务器B发现ping不通，但是服务器B本身是正常的，其他服务器都能ping通服务器B。
问题： 作为SRE工程师，你会怎么排查这个问题？请详细说明你的排查思路和具体步骤。
1. 首先A ping一下其他服务器看ping不ping的通
2. A检查一下有没有开放防火墙的ping请求 ICMP协议
3. ip route get ${IP} 检查特定路由转发情况，查看是不是没有路由或者网关不可达
4. ping一下网关
4. 检查完整路由表，看是不是缺少了跳到B服务器的路由
5. 检查网卡开没开
4. 检查B服务器的防火墙策略，看是不是没接受防火墙的ping请求 ICMP协议
5. 如果是云服务器，需要检查云服务器安全组，看是不是没开放A网段的入站请求


路由转发，路由表
ip route get ${IP}查看到特定ip的路径情况
可能的输出是
183.2.172.177 via 10.1.12.1 dev eth0 src 10.1.12.4 uid 0 
    cache 

网关情况怎么看
ip route show | grep default

本地到外网的网络转发
地服务器 → eth0网卡 → 网关 → 路由器 → 交换机 → 目标服务器c

常见的负载均衡算法有哪些？请简单说明轮询(Round Robin)和加权轮询(Weighted Round Robin)的区别，以及各自适用的场景。
常见的负载均衡算法有
1.轮询
2.加权轮询
3.最少连接
4.加权最少连接

5.IP哈希
6.最短响应时间

HTTP和HTTPS的区别是什么？HTTPS的握手过程是怎样的？在生产环境中，如何排查HTTPS证书相关的问题？
1.端口上 HTTP是80，HTTPS是443
2. HTTPS是加密数据传输的，而http不是
3. https需要用证书证明服务器的可信，证明服务器不是钓鱼服务器。

https握手过程
1. 客户端向服务器say hello，发送可支持的加密套件，随机字符等。
2. 服务器接收到随机字符，发送给服务器包含有公钥的证书，以及随机字符
3. 客户端使用证书里的公钥，对预密钥进行加密，发送给服务器(公钥加密的密文只能用私有钥进行解密)
4. 服务器用私钥进行解密。双方同时用 预密钥+客户端随机数+服务器随机数，采用之前
约定的算法进行加密，生成主密钥
5. 随后双方都使用主密钥进行通讯的加密解密

可能需要检查证书是否过期，证书的配置的域名匹不匹配，以及证书链完不完整